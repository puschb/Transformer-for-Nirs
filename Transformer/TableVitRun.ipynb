{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "    -*- coding: utf-8 -*-\n",
    "    @Time   :2021/011/12 13:10\n",
    "    @Author : Pengyou FU\n",
    "    @blogs  : https://blog.csdn.net/Echo_Code?spm=1000.2115.3001.5343\n",
    "    @github : https://github.com/FuSiry/Transformer-for-Nirs\n",
    "    @WeChat : Fu_siry\n",
    "    @License：Apache-2.0 license\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import accuracy_score,auc,roc_curve,precision_recall_curve,f1_score, precision_score, recall_score\n",
    "import torch.optim as optim\n",
    "from VitNet import ViT\n",
    "from DataLoad import DataLoad, BATCH_SIZE, Test_Batch_Size,TableDataLoad\n",
    "from EarlyStop import EarlyStopping\n",
    "# from bohb import BOHB\n",
    "import configspace as cs\n",
    "import  time\n",
    "# from torchsummary import summary\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def modeltrian(tp, EPOCH, LR, test_ratio, start, end, ncls, psize, depth, heads, mlp_dim, path):\n",
    "\n",
    "    global NetPath\n",
    "\n",
    "\n",
    "    data_train, data_test = TableDataLoad(tp, test_ratio, start, end, seed=80)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    train_result_path = './/Result//Train//transfomertable.csv'\n",
    "    test_result_path = './/Result//Test//transfomertable.csv'\n",
    "\n",
    "\n",
    "    store_path = path\n",
    "\n",
    "    model = ViT(\n",
    "                    num_classes = ncls,\n",
    "                    image_size = (end-start, 1),  # image size is a tuple of (height, width)\n",
    "                    patch_size = (psize, 1),    # patch size is a tuple of (height, width)\n",
    "                    dim = 2048, #1024 self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "                    depth = depth, #encoder和decoder的深度\n",
    "                    heads = heads, #注意力机制的数量\n",
    "                    mlp_dim = mlp_dim, #2048 encoder注意力机制后接多层全连接层\n",
    "                    dropout = 0.1,\n",
    "                    emb_dropout = 0.1\n",
    "                    ).to(device)\n",
    "\n",
    "    # summary(model, (1, 2000, 1), batch_size=1, device=\"cuda\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)  # 损失函数为焦损函数，多用于类别不平衡的多分类问题\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)  # 优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n",
    "    early_stopping = EarlyStopping(patience=30, delta=1e-4, path=store_path, verbose=False)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, verbose=1, eps=1e-07,\n",
    "                                                           patience=10)\n",
    "    print(\"This is VitRun\")\n",
    "    print(\"Start Training!\")  # 定义遍历数据集的次数\n",
    "    with open(train_result_path, \"w\") as f1:\n",
    "        with open(test_result_path, \"w\") as f2:\n",
    "            f1.write(\"{},{},{}\".format((\"epoch\"), (\"loss\"), (\"acc\")))  # 写入数据\n",
    "            f1.write('\\n')\n",
    "            f2.write(\"{},{},{}\".format((\"epoch\"), (\"loss\"), (\"acc\")))  # 写入数据\n",
    "            f2.write('\\n')\n",
    "            for epoch in range(EPOCH):\n",
    "                for i, data in enumerate(train_loader):  # gives batch data, normalize x when iterate train_loader\n",
    "                    sum_loss = []\n",
    "                    model.train()  # 不训练\n",
    "                    inputs, labels = data  # 输入和标签都等于data\n",
    "                    inputs = Variable(inputs).type(torch.FloatTensor).to(device)  # batch x\n",
    "                    labels = Variable(labels).type(torch.LongTensor).to(device)  # batch y\n",
    "                    output = model(inputs)  # cnn output\n",
    "                    loss = criterion(output, labels)  # cross entropy loss\n",
    "                    optimizer.zero_grad()  # clear gradients for this training step\n",
    "                    loss.backward()  # backpropagation, compute gradients\n",
    "                    optimizer.step()  # apply gradients\n",
    "                    _, predicted = torch.max(output.data,1)  # _ , predicted这样的赋值语句，表示忽略第一个返回值，把它赋值给 _， 就是舍弃它的意思，预测值＝output的第一个维度\n",
    "                    y_predicted = predicted.cpu().numpy()\n",
    "                    label = labels.cpu().numpy()\n",
    "                    acc = accuracy_score(label, y_predicted)\n",
    "                    # print(\"trian:epoch = {:} Loss = {:.4f}  Acc= {:.4f}\".format((epoch + 1), (loss.item()),(acc)))  # 训练次数，总损失，精确度\n",
    "                    # f1.write(\"{:},{:.4f},{:.4f}\".format((epoch + 1), (loss.item()), (acc)))  # 写入数据\n",
    "                    # f1.write('\\n')\n",
    "                    # f1.flush()\n",
    "                    sum_loss.append(loss.item())\n",
    "                avg_loss = np.mean(sum_loss)\n",
    "\n",
    "\n",
    "                with torch.no_grad():  # 无梯度\n",
    "                    test_loss = []\n",
    "                    for i, data in enumerate(test_loader):\n",
    "                        model.eval()  # 不训练\n",
    "                        inputs, labels = data  # 输入和标签都等于data\n",
    "                        inputs = Variable(inputs).type(torch.FloatTensor).to(device)  # batch x\n",
    "                        labels = Variable(labels).type(torch.LongTensor).to(device)  # batch y\n",
    "                        outputs = model(inputs)  # 输出等于进入网络后的输入\n",
    "                        loss = criterion(outputs, labels)  # cross entropy loss\n",
    "                        _, predicted = torch.max(outputs.data,1)  # _ , predicted这样的赋值语句，表示忽略第一个返回值，把它赋值给 _， 就是舍弃它的意思，预测值＝output的第一个维度 ，取得分最高的那个类 (outputs.data的索引号)\n",
    "                        y_predicted = predicted.cpu().numpy()\n",
    "                        label = labels.cpu().numpy()\n",
    "                        acc = accuracy_score(label, y_predicted)\n",
    "                        test_loss.append(loss.item())\n",
    "                        # print(\"test:epoch = {:}   Acc= {:.4f}\".format((epoch + 1) , (acc)))\n",
    "                        # f2.write(\"{},{:.4f},{:.4f}\".format((epoch + 1), (loss.item()), (acc)))  # 写入数据\n",
    "                        # f2.write('\\n')\n",
    "                        # f2.flush()\n",
    "            # 将每次测试结果实时写入acc.txt文件中\n",
    "\n",
    "\n",
    "\n",
    "def modeltest(tp, test_ratio, start, end, ncls, psize, depth, heads, mlp_dim, path):\n",
    "    # _, data_test = DataLoad('tou', test_ratio, start, end)\n",
    "    data_train, data_test = TableDataLoad(tp, test_ratio, start, end, seed=80)\n",
    "    test_loader = torch.utils.data.DataLoader(data_test, batch_size=Test_Batch_Size, shuffle=True)\n",
    "    model = ViT(\n",
    "                    num_classes = ncls,\n",
    "                    image_size = (end-start, 1),  # image size is a tuple of (height, width)\n",
    "                    patch_size = (psize, 1),    # patch size is a tuple of (height, width)\n",
    "                    dim = 2048, #1024,\n",
    "                    depth = depth,\n",
    "                    heads = heads,\n",
    "                    mlp_dim = mlp_dim, #2048, 1024\n",
    "                    dropout = 0.1,\n",
    "                    emb_dropout = 0.1\n",
    "                    ).to(device)\n",
    "    # store_path = './/model//all//transform'+'{}new.pt'.format(int(10-10*(test_ratio)))\n",
    "    store_path = path\n",
    "    model.load_state_dict(torch.load(store_path))\n",
    "    acc_list = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        model.eval()  # 不训练\n",
    "        inputs, labels = data  # 输入和标签都等于data\n",
    "        inputs = Variable(inputs).type(torch.FloatTensor).to(device)  # batch x\n",
    "        labels = Variable(labels).type(torch.LongTensor).to(device)  # batch y\n",
    "        outputs = model(inputs)  # 输出等于进入网络后的输入\n",
    "        _, predicted = torch.max(outputs.data,1)  # _ , predicted这样的赋值语句，表示忽略第一个返回值，把它赋值给 _， 就是舍弃它的意思，预测值＝output的第一个维度 ，取得分最高的那个类 (outputs.data的索引号)\n",
    "        y_predicted = predicted.cpu().numpy()\n",
    "        label = labels.cpu().numpy()\n",
    "        acc = accuracy_score(label, y_predicted)\n",
    "        acc_list.append(acc)\n",
    "    # print(\"Acc= {:.4f}\".format(np.mean(acc_list)))\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "\n",
    "class ConfusionMatrix(object):\n",
    "\n",
    "    def __init__(self, num_classes: int, labels: list):\n",
    "        self.matrix = np.zeros((num_classes, num_classes))  # 初始化混淆矩阵，元素都为0\n",
    "        self.num_classes = num_classes  # 类别数量，本例数据集类别为5\n",
    "        self.labels = labels  # 类别标签\n",
    "\n",
    "    def update(self, preds, labels):\n",
    "        for p, t in zip(preds, labels):  # pred为预测结果，labels为真实标签\n",
    "            self.matrix[p, t] += 1  # 根据预测结果和真实标签的值统计数量，在混淆矩阵相应位置+1\n",
    "\n",
    "    def summary(self):  # 计算指标函数\n",
    "        # calculate accuracy\n",
    "        sum_TP = 0\n",
    "        n = np.sum(self.matrix)\n",
    "        for i in range(self.num_classes):\n",
    "            sum_TP += self.matrix[i, i]  # 混淆矩阵对角线的元素之和，也就是分类正确的数量\n",
    "        acc = sum_TP / n  # 总体准确率\n",
    "        print(\"the model accuracy is \", acc)\n",
    "\n",
    "        # kappa\n",
    "        sum_po = 0\n",
    "        sum_pe = 0\n",
    "        for i in range(len(self.matrix[0])):\n",
    "            sum_po += self.matrix[i][i]\n",
    "            row = np.sum(self.matrix[i, :])\n",
    "            col = np.sum(self.matrix[:, i])\n",
    "            sum_pe += row * col\n",
    "        po = sum_po / n\n",
    "        pe = sum_pe / (n * n)\n",
    "        # print(po, pe)\n",
    "        kappa = round((po - pe) / (1 - pe), 3)\n",
    "        # print(\"the model kappa is \", kappa)\n",
    "\n",
    "        return str(acc)\n",
    "\n",
    "    def plot(self):  # 绘制混淆矩阵\n",
    "        matrix = self.matrix\n",
    "        print(matrix)\n",
    "        plt.imshow(matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "        # 设置x轴坐标label\n",
    "        plt.xticks(range(self.num_classes), self.labels, rotation=45)\n",
    "        # 设置y轴坐标label\n",
    "        plt.yticks(range(self.num_classes), self.labels)\n",
    "        # 显示colorbar\n",
    "        plt.colorbar()\n",
    "        plt.xlabel('True Labels')\n",
    "        plt.ylabel('Predicted Labels')\n",
    "        plt.title('Confusion matrix (acc=' + self.summary() + ')')\n",
    "\n",
    "        # 在图中标注数量/概率信息\n",
    "        thresh = matrix.max() / 2\n",
    "        for x in range(self.num_classes):\n",
    "            for y in range(self.num_classes):\n",
    "                # 注意这里的matrix[y, x]不是matrix[x, y]\n",
    "                info = int(matrix[y, x])\n",
    "                plt.text(x, y, info,\n",
    "                         verticalalignment='center',\n",
    "                         horizontalalignment='center',\n",
    "                         color=\"white\" if info > thresh else \"black\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def model4AUCtest(tp, test_ratio, start, end, ncls, psize, depth, heads, mlp_dim, path):\n",
    "    #_, data_test = DataLoad(tp, test_ratio, start, end)\n",
    "    data_train, data_test = TableDataLoad(tp, test_ratio, start, end, seed=80)\n",
    "    test_loader = torch.utils.data.DataLoader(data_test, batch_size=Test_Batch_Size, shuffle=True)\n",
    "    model = ViT(\n",
    "                    num_classes = ncls,\n",
    "                    image_size = (end-start, 1),  # image size is a tuple of (height, width)\n",
    "                    patch_size = (psize, 1),    # patch size is a tuple of (height, width)\n",
    "                    dim = 2048, #1024,\n",
    "                    depth = depth,\n",
    "                    heads = heads,\n",
    "                    mlp_dim = mlp_dim, #2048, 1024\n",
    "                    dropout = 0.1,\n",
    "                    emb_dropout = 0.1\n",
    "                    ).to(device)\n",
    "    # store_path = './/model//all//transform'+'{}new.pt'.format(int(10-10*(test_ratio)))\n",
    "    store_path = path\n",
    "    model.load_state_dict(torch.load(store_path))\n",
    "    labels = [0, 1, 2, 3]\n",
    "    # tomato_DICT = {'0': 'Bacterial_spot', '1': 'Early_blight', '2': 'healthy', '3': 'Late_blight', '4': 'Leaf_Mold'}\n",
    "    # label = [label for _, label in class_indict.items()]\n",
    "    confusion = ConfusionMatrix(num_classes=4, labels=labels)\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        model.eval()  # 不训练\n",
    "        inputs, labels = data  # 输入和标签都等于data\n",
    "        inputs = Variable(inputs).type(torch.FloatTensor).to(device)  # batch x\n",
    "        labels = Variable(labels).type(torch.LongTensor).to(device)  # batch y\n",
    "        outputs = model(inputs)  # 输出等于进入网络后的输入\n",
    "        y_proba = outputs.data.cpu().numpy()\n",
    "        _, predicted = torch.max(outputs.data,1)  # _ , predicted这样的赋值语句，表示忽略第一个返回值，把它赋值给 _， 就是舍弃它的意思，预测值＝output的第一个维度 ，取得分最高的那个类 (outputs.data的索引号)\n",
    "        y_predicted = predicted.cpu().numpy()\n",
    "        label = labels.cpu().numpy()\n",
    "\n",
    "        y_one_hot = label_binarize(label, classes=[0, 1, 2, 3])\n",
    "        # ACC\n",
    "        acc = accuracy_score(label, y_predicted)\n",
    "        precis = precision_score(label, y_predicted, average='weighted')\n",
    "        reca = recall_score(label, y_predicted, average='weighted')\n",
    "\n",
    "        # labels_name = [0, 1, 2, 3]\n",
    "        # arry = metrics.confusion_matrix(y_true=label, y_pred=y_predicted, labels=labels_name)  # 生成混淆矩阵\n",
    "\n",
    "        confusion.update(y_predicted, label)\n",
    "\n",
    "\n",
    "        # FPR,TPR\n",
    "        false_positive_rate, true_positive_rate, _ = roc_curve(y_one_hot.ravel(), y_proba.ravel())\n",
    "        # new_tpr\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        new_true_positive_rate = np.interp(mean_fpr, false_positive_rate, true_positive_rate)\n",
    "        # AUC\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        # Recall、Precision\n",
    "        precision, recall, _ = precision_recall_curve(y_one_hot.ravel(), y_proba.ravel())\n",
    "        # new_recall\n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "        new_precision = np.interp(mean_recall, precision, recall)\n",
    "        # new_precision = np.interp(mean_recall, recall, precision)\n",
    "        # F1\n",
    "        F1 = f1_score(label, y_predicted, average='weighted')\n",
    "        # F2 = f1_score(y_test,y_pred,average='macro')\n",
    "        # F3 = f1_score(y_test,y_pred,average='micro')\n",
    "\n",
    "        # # runing_time\n",
    "        # run_time = end - start\n",
    "    # confusion.plot()\n",
    "    # confusion.summary()\n",
    "\n",
    "    return acc, precis, reca, F1, roc_auc #new_true_positive_rate, new_precision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    name = 'raw'\n",
    "\n",
    "    sotre_path = './/model//Table//transformertable1125'+'{}.pt'.format(name)\n",
    "\n",
    "    # modeltrian(tp=name, EPOCH=200, LR=0.0001, test_ratio=0.319,\n",
    "    #                               start=0, end=400, ncls=4, psize=10, depth=3, heads=12, mlp_dim=1024,\n",
    "    #                               path=sotre_path)  # depth=6, heads=10, 12, 14\n",
    "    acc, precis, reca, F1, roc_auc = model4AUCtest(tp=name,test_ratio=0.319,\n",
    "               start=0, end=400, ncls=4, psize=10, depth=3, heads=12, mlp_dim=1024, path=sotre_path)  # depth=6, heads=10, 12, 14\n",
    "\n",
    "    print(\"acc:{}, precis:{}, recall:{}, F1:{}, auc:{}\".format(acc, precis, reca, F1, roc_auc))\n",
    "\n",
    "    #     acc = modeltest(tp=name, test_ratio=0.319, start=0, end=400,\n",
    "    #                            ncls=4, psize=10, depth=3, heads=12, mlp_dim=1024, path=sotre_path)\n",
    "    #     print(acc)\n",
    "    #     # print(arry)\n",
    "    #     # with open(result_path, \"a\") as file:\n",
    "    #     #     file.write(\"{}, {}\".format(\n",
    "    #     #         name, acc))  # 写入数据\n",
    "    #     #     file.write('\\n')\n",
    "\n",
    "    # list = [5,10,25,40,50,80,100]\n",
    "    #\n",
    "    # for name in list:\n",
    "    #     sotre_path = './/model//Table//transformertable'+'{}.pt'.format(name)\n",
    "    #\n",
    "    #\n",
    "    #     result_path = './/Result//Table//transformertabale'+'.csv'\n",
    "    #     modeltrian(tp='raw', EPOCH=200, LR=0.0001, test_ratio=0.319,\n",
    "    #                                   start=0, end=400, ncls=4, psize=name, depth=3, heads=12, mlp_dim=12,\n",
    "    #                                   path=sotre_path)  # depth=6, heads=10, 12, 14\n",
    "    #     acc = modeltest(tp='raw', test_ratio=0.319, start=0, end=400,\n",
    "    #                            ncls=4, psize=name, depth=3, heads=12, mlp_dim=12, path=sotre_path)\n",
    "    #     print(acc)\n",
    "    #\n",
    "    #     with open(result_path, \"a\") as file:\n",
    "    #         file.write(\"{}, {}, {}\".format(\n",
    "    #             'psize', acc, name))  # 写入数据\n",
    "    #         file.write('\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
